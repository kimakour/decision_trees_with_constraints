{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "#from BinaryDecisionTreeConstraints.BinaryDecisionTreeConstraints import Node\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "from collections import Counter\n",
    "import re\n",
    "from optbinning import OptimalBinning\n",
    "from pandas.api.types import is_string_dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node: \n",
    "    def __init__(\n",
    "        self, \n",
    "        Y: list,\n",
    "        X: pd.DataFrame,\n",
    "        min_samples_split=None,\n",
    "        max_depth=None,\n",
    "        depth=None,\n",
    "        node_type=None,\n",
    "        rule=None,\n",
    "        stop=None,\n",
    "        dataframe_constraints= pd.DataFrame([[0,0,0,0]]).rename(columns={0:\"path\",1:\"feature\",2:\"type_feature\", 3:\"forced_value\"}),\n",
    "        path=''\n",
    "    ): \n",
    "        self.Y = Y \n",
    "        self.X = X\n",
    "        \n",
    "        self.min_samples_split = min_samples_split if min_samples_split else 500\n",
    "        self.max_depth = max_depth if max_depth else 5\n",
    "\n",
    "        self.depth = depth if depth else 0\n",
    "\n",
    "        self.features = list(self.X.columns)\n",
    "        self.features_types = self.X.dtypes.apply(lambda x : \"categorical\" if is_string_dtype(x)  else \"numerical\").tolist()\n",
    "        self.list_features = list(zip(self.features, self.features_types))\n",
    "\n",
    "        self.node_type = node_type if node_type else 'root'\n",
    "\n",
    "        self.rule = rule if rule else \"\"\n",
    "\n",
    "        self.counts = Counter(Y)\n",
    "\n",
    "        counts_sorted = list(sorted(self.counts.items(), key=lambda item: item[1]))\n",
    "\n",
    "        yhat = None\n",
    "        y_prob = None \n",
    "        if len(counts_sorted) > 0:\n",
    "            yhat = counts_sorted[-1][0]\n",
    "            y_prob = np.mean(Y)\n",
    "\n",
    "        self.yhat = yhat\n",
    "        self.y_prob = y_prob\n",
    "\n",
    "        self.n = len(Y)\n",
    "\n",
    "        self.left = None \n",
    "        self.right = None \n",
    "        self.best_feature = None \n",
    "        self.best_value = None\n",
    "        self.best_type = None\n",
    "        \n",
    "        self.stop = stop\n",
    "        self.dataframe_constraints = dataframe_constraints\n",
    "        self.path = path + str(self.depth)+self.node_type\n",
    "        \n",
    "    def best_split(self) -> tuple:\n",
    "        \"\"\"\n",
    "        Given the X features and Y targets calculates the best split \n",
    "        for a decision tree\n",
    "        \"\"\"\n",
    "        # Creating a dataset for spliting\n",
    "        df = self.X.copy()\n",
    "        df['Y'] = self.Y\n",
    "\n",
    "\n",
    "        # Default best feature and split\n",
    "        best_feature = None\n",
    "        best_value = None\n",
    "        best_type = None \n",
    "        number_level = self.depth\n",
    "        list_scores = list()\n",
    "        dataframe_constraints = self.dataframe_constraints[self.dataframe_constraints.feature.isin(self.features)]\n",
    "        \n",
    "        echantillon = dataframe_constraints[(dataframe_constraints.path == self.path)]\n",
    "\n",
    "        if len(echantillon)>0:\n",
    "            best_feature = echantillon.feature.values[0]\n",
    "            feature_type = echantillon.type_feature.values[0]\n",
    "            sous_ech_constraint = echantillon[((echantillon.forced_value!=\"\") & (dataframe_constraints.type_feature==\"categorical\")) |((~dataframe_constraints.forced_value.isna()) & (dataframe_constraints.type_feature==\"numerical\"))]\n",
    "            if len(sous_ech_constraint)>0:\n",
    "                best_value = sous_ech_constraint.forced_value.values[0]\n",
    "                best_type = feature_type\n",
    "\n",
    "                return (best_feature, best_value, best_type)\n",
    "            else:\n",
    "                x = self.X[best_feature].values\n",
    "                y = self.Y\n",
    "                optb = OptimalBinning(name=best_feature, dtype=feature_type, solver=\"cp\",max_n_bins = 2, min_bin_size = min(0.5, self.stop / len(df)))\n",
    "                optb.fit(x, y)\n",
    "                binning_table = optb.binning_table.build()\n",
    "                binning_table = binning_table[~binning_table[\"Bin\"].isin( [\"Special\",\"Missing\"])]\n",
    "                if len(binning_table)>2:\n",
    "                    list_scores.append([number_level,best_feature,feature_type,\n",
    "                        binning_table.loc[0, \"Bin\"], \n",
    "                        binning_table.loc[1, \"Bin\"],\n",
    "                        binning_table.loc[1, \"Count\"],\n",
    "                        binning_table.loc[0, \"Count\"],\n",
    "                        binning_table.loc[0, \"Event rate\"],\n",
    "                        binning_table.loc[1, \"Event rate\"]])\n",
    "        else:       \n",
    "            for feature, feature_type in self.list_features :\n",
    "                x = self.X[feature].values\n",
    "                y = self.Y\n",
    "                optb = OptimalBinning(name=feature, dtype=feature_type, solver=\"cp\",max_n_bins = 2, \n",
    "                                      min_bin_size = min(0.5, self.stop / len(df)))\n",
    "                optb.fit(x, y)\n",
    "                binning_table = optb.binning_table.build()\n",
    "                binning_table = binning_table[~binning_table[\"Bin\"].isin( [\"Special\",\"Missing\"])]\n",
    "                if len(binning_table)>2:\n",
    "                    list_scores.append([number_level,feature,feature_type, \n",
    "                                        binning_table.loc[0, \"Bin\"], \n",
    "                                        binning_table.loc[1, \"Bin\"],\n",
    "                                        binning_table.loc[1, \"Count\"],\n",
    "                                        binning_table.loc[0, \"Count\"],\n",
    "                                        binning_table.loc[0, \"Event rate\"], \n",
    "                                        binning_table.loc[1, \"Event rate\"]])\n",
    "                \n",
    "        dataframe_scores = pd.DataFrame(list_scores)\n",
    "        if len(dataframe_scores) >0 :\n",
    "            dataframe_scores = dataframe_scores.rename(columns={0:\"level\", 1:\"feature\", 2: \"feature_type\", 3:\"bin_0\",\n",
    "                                                                4: \"bin_1\", 5:\"count_0\", 6: \"count_1\", 7:\"event_rate_0\", 8:\"event_rate_1\"})\n",
    "            dataframe_scores['diff_rate'] = np.abs(dataframe_scores['event_rate_0']- dataframe_scores['event_rate_1'])\n",
    "            max_dataframe_scores = dataframe_scores.groupby(['level'])['diff_rate'].max().reset_index().merge(dataframe_scores, how=\"left\", on=['level', 'diff_rate'])\n",
    "            best_feature = max_dataframe_scores['feature'].values[0]\n",
    "            best_type = max_dataframe_scores['feature_type'].values[0]\n",
    "\n",
    "            if best_type == \"categorical\":\n",
    "                best_value = max_dataframe_scores['bin_0'].values[0]\n",
    "            else:\n",
    "                best_value = float(re.findall(\"\\d+\\.\\d+\", max_dataframe_scores[\"bin_0\"].values[0])[0])\n",
    "\n",
    "        return (best_feature, best_value, best_type)\n",
    "    \n",
    "    def grow_tree(self):\n",
    "        df = self.X.copy()\n",
    "        df['Y'] = self.Y\n",
    "        if (self.depth < self.max_depth) and (self.n >= self.min_samples_split):\n",
    "            best_feature, best_value, best_type = self.best_split()\n",
    "\n",
    "            if best_feature is not None:\n",
    "                # Saving the best split to the current node \n",
    "                self.best_feature = best_feature\n",
    "                self.best_value = best_value\n",
    "                self.best_type = best_type\n",
    "                print(self.depth, best_feature,best_value, best_type )\n",
    "                if self.best_type==\"categorical\":\n",
    "                    left_df, right_df = df[df[best_feature].isin(best_value)].copy(), df[~df[best_feature].isin(best_value)].copy()\n",
    "                    left = Node(left_df['Y'].values.tolist(), \n",
    "                                left_df[self.features], \n",
    "                                depth=self.depth + 1, \n",
    "                                max_depth=self.max_depth, \n",
    "                                min_samples_split=self.min_samples_split, \n",
    "                                node_type='left_node',\n",
    "                                rule =\" {best_feature} in {best_value} \".format(best_feature=best_feature, best_value = best_value),\n",
    "                                stop = self.stop,\n",
    "                                dataframe_constraints = self.dataframe_constraints,\n",
    "                                path=self.path)\n",
    "                    \n",
    "                    self.left = left \n",
    "                    self.left.grow_tree()\n",
    "                    \n",
    "                    right = Node(\n",
    "                        right_df['Y'].values.tolist(), \n",
    "                        right_df[self.features], \n",
    "                        depth=self.depth + 1, \n",
    "                        max_depth=self.max_depth, \n",
    "                        min_samples_split=self.min_samples_split,\n",
    "                        node_type='right_node',\n",
    "                        rule =\" {best_feature} not in {best_value} \".format(best_feature=best_feature, best_value = best_value),\n",
    "                        stop = self.stop,\n",
    "                        dataframe_constraints = self.dataframe_constraints, \n",
    "                        path=self.path\n",
    "                    )\n",
    "                    \n",
    "                    self.right = right\n",
    "                    self.right.grow_tree()\n",
    "\n",
    "                else:\n",
    "                    left_df, right_df = df[df[best_feature]<=best_value].copy(), df[df[best_feature]>best_value].copy()\n",
    "                    left = Node(left_df['Y'].values.tolist(), \n",
    "                                left_df[self.features], \n",
    "                                depth=self.depth + 1, \n",
    "                                max_depth=self.max_depth, \n",
    "                                min_samples_split=self.min_samples_split, \n",
    "                                node_type='left_node',\n",
    "                                rule = f\"{best_feature} <= {round(best_value, 3)}\",\n",
    "                                stop = self.stop, \n",
    "                                dataframe_constraints = self.dataframe_constraints, \n",
    "                                path=self.path)\n",
    "                    \n",
    "                    self.left = left \n",
    "                    self.left.grow_tree()\n",
    "                    \n",
    "                    right = Node(\n",
    "                        right_df['Y'].values.tolist(), \n",
    "                        right_df[self.features], \n",
    "                        depth=self.depth + 1, \n",
    "                        max_depth=self.max_depth, \n",
    "                        min_samples_split=self.min_samples_split,\n",
    "                        node_type='right_node',\n",
    "                        rule =f\"{best_feature}> {round(best_value, 3)}\",\n",
    "                        stop = self.stop,  \n",
    "                        dataframe_constraints = self.dataframe_constraints, \n",
    "                        path=self.path)\n",
    "                    \n",
    "                    self.right = right\n",
    "                    self.right.grow_tree()\n",
    "                    \n",
    "        \n",
    "        \n",
    "    def print_tree(self, result=None):\n",
    "        \n",
    "        if result is None:\n",
    "            result = []\n",
    " \n",
    "        dictionnaire = dict(self.counts)\n",
    "        result.append([self.path, self.rule,dictionnaire, round(self.y_prob, 3), self.yhat])\n",
    "        if self.left is not None: \n",
    "            self.left.print_tree(result=result)\n",
    "        if self.right is not None:\n",
    "            self.right.print_tree(result=result)\n",
    "        return result\n",
    "    \n",
    "    \n",
    "    def print_tree_dataframe(self):\n",
    "        dataframe = pd.DataFrame(self.print_tree())\n",
    "        dataframe = dataframe.rename(columns={0:\"path\",1:\"rule\",2:\"distribution\",3:\"probabilite\" ,4:\"prediction\"})\n",
    "        return dataframe\n",
    "\n",
    "\n",
    "    def predict(self, X:pd.DataFrame):\n",
    "        \"\"\"\n",
    "        Batch prediction method\n",
    "        \"\"\"\n",
    "        predictions = []\n",
    "\n",
    "        for _, x in X.iterrows():\n",
    "            values = {}\n",
    "            for feature in self.features:\n",
    "                values.update({feature: x[feature]})\n",
    "            \n",
    "        \n",
    "            predictions.append(self.predict_obs(values))\n",
    "            \n",
    "        predictions = pd.DataFrame(predictions)\n",
    "        predictions = predictions.rename(columns={0:\"prediction\",1:\"probability\"})\n",
    "        \n",
    "        return predictions\n",
    "\n",
    "    def predict_obs(self, values: dict) -> int:\n",
    "        \"\"\"\n",
    "        Method to predict the class given a set of features\n",
    "        \"\"\"\n",
    "        cur_node = self\n",
    "        while (cur_node.depth < cur_node.max_depth) and (cur_node.best_feature is not None):\n",
    "            # Traversing the nodes all the way to the bottom\n",
    "            best_feature = cur_node.best_feature\n",
    "            best_value = cur_node.best_value\n",
    "            type_feature = cur_node.best_type\n",
    "\n",
    "            if cur_node.n < cur_node.min_samples_split:\n",
    "                break \n",
    "                \n",
    "            \n",
    "            if type_feature == \"categorical\":\n",
    "                if (values.get(best_feature) in best_value ):\n",
    "                    if self.left is not None:\n",
    "                        cur_node = cur_node.left\n",
    "                else:\n",
    "                    if self.right is not None:\n",
    "                        cur_node = cur_node.right\n",
    "            else:\n",
    "                if (values.get(best_feature) < best_value):\n",
    "                    if self.left is not None:\n",
    "                        cur_node = cur_node.left\n",
    "                else:\n",
    "                    if self.right is not None:\n",
    "                        cur_node = cur_node.right\n",
    "            \n",
    "        return cur_node.yhat, round(cur_node.y_prob,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the X and Y matrices\n",
    "Y = df_train['Survived'].values\n",
    "X = df_train[['Sex','Cabin','Age','Fare','Pclass','Embarked']]\n",
    "# Saving the feature list \n",
    "features = list(X.columns)\n",
    "nb_stop = np.ceil(len(df_train) * 0.03)\n",
    "list_constraints = [ [\"0root\",'Embarked',\"categorical\",\"\"], [\"0root1left_node\",'Pclass',\"numerical\",1.5]]\n",
    "dataframe_constraints = pd.DataFrame(list_constraints)\n",
    "dataframe_constraints = dataframe_constraints.rename(columns={0:\"path\",1:\"feature\",2:\"type_feature\", 3:\"forced_value\"})\n",
    "hp = {\n",
    "    \"max_depth\": 4,\n",
    "    \"stop\" : nb_stop,\n",
    "    \"dataframe_constraints\": dataframe_constraints\n",
    "}\n",
    "\n",
    "root = Node(Y, X, **hp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kaci-\\Anaconda3\\envs\\mynewenv\\lib\\site-packages\\ipykernel_launcher.py:79: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "C:\\Users\\kaci-\\Anaconda3\\envs\\mynewenv\\lib\\site-packages\\pandas\\core\\algorithms.py:465: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  return f(comps, values)\n",
      "C:\\Users\\kaci-\\Anaconda3\\envs\\mynewenv\\lib\\site-packages\\ipykernel_launcher.py:79: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "C:\\Users\\kaci-\\Anaconda3\\envs\\mynewenv\\lib\\site-packages\\pandas\\core\\algorithms.py:465: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  return f(comps, values)\n",
      "C:\\Users\\kaci-\\Anaconda3\\envs\\mynewenv\\lib\\site-packages\\pandas\\core\\algorithms.py:465: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  return f(comps, values)\n",
      "C:\\Users\\kaci-\\Anaconda3\\envs\\mynewenv\\lib\\site-packages\\pandas\\core\\algorithms.py:465: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  return f(comps, values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Embarked ['S' 'Q'] categorical\n",
      "1 Pclass 1.5 numerical\n",
      "2 Sex ['male'] categorical\n"
     ]
    }
   ],
   "source": [
    "root.grow_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>rule</th>\n",
       "      <th>distribution</th>\n",
       "      <th>probabilite</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0root</td>\n",
       "      <td></td>\n",
       "      <td>{0: 549, 1: 342}</td>\n",
       "      <td>0.384</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0root1left_node</td>\n",
       "      <td>Embarked in ['S' 'Q']</td>\n",
       "      <td>{0: 474, 1: 247}</td>\n",
       "      <td>0.343</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0root1left_node2left_node</td>\n",
       "      <td>Pclass &lt;= 1.5</td>\n",
       "      <td>{1: 75, 0: 54}</td>\n",
       "      <td>0.581</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0root1left_node2right_node</td>\n",
       "      <td>Pclass&gt; 1.5</td>\n",
       "      <td>{0: 420, 1: 172}</td>\n",
       "      <td>0.291</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0root1left_node2right_node3left_node</td>\n",
       "      <td>Sex in ['male']</td>\n",
       "      <td>{0: 350, 1: 52}</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0root1left_node2right_node3right_node</td>\n",
       "      <td>Sex not in ['male']</td>\n",
       "      <td>{1: 120, 0: 70}</td>\n",
       "      <td>0.632</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0root1right_node</td>\n",
       "      <td>Embarked not in ['S' 'Q']</td>\n",
       "      <td>{1: 95, 0: 75}</td>\n",
       "      <td>0.559</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    path                         rule  \\\n",
       "0                                  0root                                \n",
       "1                        0root1left_node       Embarked in ['S' 'Q']    \n",
       "2              0root1left_node2left_node                Pclass <= 1.5   \n",
       "3             0root1left_node2right_node                  Pclass> 1.5   \n",
       "4   0root1left_node2right_node3left_node             Sex in ['male']    \n",
       "5  0root1left_node2right_node3right_node         Sex not in ['male']    \n",
       "6                       0root1right_node   Embarked not in ['S' 'Q']    \n",
       "\n",
       "       distribution  probabilite  prediction  \n",
       "0  {0: 549, 1: 342}        0.384           0  \n",
       "1  {0: 474, 1: 247}        0.343           0  \n",
       "2    {1: 75, 0: 54}        0.581           1  \n",
       "3  {0: 420, 1: 172}        0.291           0  \n",
       "4   {0: 350, 1: 52}        0.129           0  \n",
       "5   {1: 120, 0: 70}        0.632           1  \n",
       "6    {1: 95, 0: 75}        0.559           1  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root.print_tree_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### + rajouter la condition du gain + trouver un moyen de plot le graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
